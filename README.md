# Product Recommendation System using Apache Spark and Apache Hadoop

## Introduction

Recommendation systems are indispensable in modern business environments due to the abundance of customer data, reviews, and product variety. They automate the real-time delivery of personalized product recommendations tailored to specific user preferences. 

This project focuses on developing a recommendation system utilizing Apache Spark and Apache Hadoop. It leverages collaborative filtering techniques to generate recommendations based on user-item interactions. Specifically, the system implements the Alternating Least Squares (ALS) algorithm on Apache Spark for fast real-time data processing.

## Technologies Used

- **Apache Spark**: Used for large-scale data processing and machine learning tasks.
- **Apache Hadoop**: Used for distributed storage and processing of large datasets.
- **Google Cloud Dataproc**: Leveraged to run Apache Spark jobs on a managed Hadoop cluster.
- **Python**: Programming language used for implementing Spark jobs and data processing pipelines.

## Architecture

The Product Recommendation System follows a typical collaborative filtering approach:

1. **Data Ingestion**: User-item interaction data is ingested from various sources such as user clicks, purchases, ratings, etc.
2. **Data Preprocessing**: Data preprocessing involves cleaning, filtering, and transforming the raw data into a suitable format for recommendation model training.
3. **Model Training**: The preprocessed data is used to train collaborative filtering models, such as Alternating Least Squares (ALS), using Apache Spark's MLlib library.
4. **Model Evaluation**: The trained models are evaluated using metrics such as Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), etc., to assess their performance.
5. **Recommendation Generation**: Once the model is trained and evaluated, it can generate personalized recommendations for users based on their past interactions with items.

## Deployment on Google Cloud Dataproc

Google Cloud Dataproc provides a managed Spark and Hadoop service that simplifies the deployment and management of Apache Spark jobs. The steps involved in deploying the Product Recommendation System on Google Cloud Dataproc are as follows:

1. **Data Upload**: Upload the dataset to Google Cloud Storage (GCS) or Hadoop Distributed File System (HDFS).
2. **Cluster Creation**: Create a Dataproc cluster with the desired configuration (number of nodes, machine types, etc.).
3. **Job Submission**: Submit Spark jobs to the Dataproc cluster using the `gcloud` command-line tool or the Dataproc API.
4. **Monitoring and Scaling**: Monitor job progress and cluster performance using the Dataproc UI. Scale the cluster up or down based on workload requirements.
5. **Results Analysis**: Analyze the recommendation results generated by the Spark jobs and fine-tune the recommendation models as needed.

## Related Work

Previous studies have addressed challenges such as cold start issues in collaborative filtering methods. Efforts have been made to introduce hybrid models, which combine collaborative and content-based filtering approaches, to mitigate these issues. Our project builds upon these efforts by implementing ALS on Spark for product recommendations. Additionally, matrix factorization techniques are incorporated into the ALS algorithm to mitigate overfitting issues commonly encountered in recommendation systems.

## Implementation and Results

The recommendation system is implemented using collaborative filtering techniques, specifically ALS algorithm, on Apache Spark. Two main methods are explored:

1. **Content-Based Filtering**: Recommends products based on user preferences and item features. It creates user profiles reflecting user preferences and suggests similar items based on past interactions. However, it heavily relies on historical data and may struggle with cold start issues.

2. **Collaborative Filtering**: Recommends products based on the preferences of similar users. It identifies neighborhoods of similar users and suggests items based on their preferences. Collaborative filtering can handle cold start issues effectively and tailors recommendations to users.

The project utilizes ALS algorithm for matrix factorization in collaborative filtering. ALS is an optimization technique to perform matrix factorization and is commonly used in recommendation systems. By tuning hyperparameters and incorporating matrix factorization techniques, the system achieves improved prediction accuracy and mitigates overfitting issues.

## Environment Setup

The recommendation system is deployed on Google Cloud Platform using Google Cloud Dataproc service. Dataproc simplifies the deployment and management of Apache Spark and Apache Hadoop clusters, allowing easy configuration and management of big data projects. 

A cluster with one master node and three worker nodes is created on Google Cloud to run the recommendation system. Dataproc enables easy monitoring of system resources, making it an ideal choice for our project.

## Conclusion

The recommendation system developed in this project utilizes Apache Spark for high-speed data processing. By leveraging collaborative filtering techniques and matrix factorization, it delivers personalized product recommendations in real-time. The system is structured based on lambda architecture, enabling real-time recommendation visibility for users. Future enhancements may include integrating advanced methods such as deep collaborative filtering and convolutional neural network-based recommendation approaches.

## Contributions

- **Report Contributions**:
  - Introduction, Related Work, and Conclusion: Phanendra
  - Implementation and Results: Jaswanth
  - Conclusion and References: Abdul
- **Code Contributions**: Jaswanth, Phanendra, and Abdul

